State sample_from_belief(Belief b){

}

Action action_prog_widen(History h){
    if(C_h.size() <= k_a * std::pow(N(h), alpha_a)){
        Action a = next_action(h);
        C_h.append(a);
    }
    Action best_a;
    double best_reward = -INFINITY;
    for(Action a : C_h){
        double reward = Q(h.append(a)) + c * std::sqrt(std::log(N(h))/ N(h.append(a)));

        // N: a count of the number of visits.
        // M: a count of the number of times that a history has been generated by the model.
        if (reward > best_reward){
            best_a = a;
        }
    }
    return best_a;
}

struct GenerativeResult{
    State s_tilde;
    Observation o;
    double reward;
}
int d_max = 5;



Action Plan(Belief b){
    for(int i = 0; i < n; i++){
        State s = sample_from_belief(b);
        simulate_pomcp_dpw(s, b, d_max);
    }
}

int main(){

}


